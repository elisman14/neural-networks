{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab456d6",
   "metadata": {},
   "source": [
    "# БФИ2001 Фаттахов Тагир"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de3eb8",
   "metadata": {},
   "source": [
    "## Лабораторная работа №8 (Генерация текста на основе \"Алисы в стране чудес\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f28b8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, Callback, TensorBoard\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e8fbd",
   "metadata": {},
   "source": [
    "Загрузка текста и преобразования в нижний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4609a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename, encoding=\"utf-8\").read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19380ac",
   "metadata": {},
   "source": [
    "Создания словаря символ - целочисленное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90cf59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a37067",
   "metadata": {},
   "source": [
    "Суммирование набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966c4c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 144679\n",
      "Total Vocab: 49\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters:\", n_chars)\n",
    "print(\"Total Vocab:\", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf084f7",
   "metadata": {},
   "source": [
    "Разделение книги на последовательности по 100 значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed7baab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 144579\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0781847",
   "metadata": {},
   "source": [
    "Нормализация данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f884509",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "X = X / float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52f67c",
   "metadata": {},
   "source": [
    "Задаём архитектуру ИНС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0a3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ccf03",
   "metadata": {},
   "source": [
    "Запись сетевых весов для каждой эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01776d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath= \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc73ca9",
   "metadata": {},
   "source": [
    "Обучение ИНС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6054b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 3.0283\n",
      "Epoch 1: loss improved from inf to 3.02829, saving model to weights-improvement-01-3.0283.hdf5\n",
      "1130/1130 [==============================] - 376s 331ms/step - loss: 3.0283\n",
      "Epoch 2/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.8168\n",
      "Epoch 2: loss improved from 3.02829 to 2.81682, saving model to weights-improvement-02-2.8168.hdf5\n",
      "1130/1130 [==============================] - 380s 336ms/step - loss: 2.8168\n",
      "Epoch 3/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.7067\n",
      "Epoch 3: loss improved from 2.81682 to 2.70670, saving model to weights-improvement-03-2.7067.hdf5\n",
      "1130/1130 [==============================] - 380s 336ms/step - loss: 2.7067\n",
      "Epoch 4/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.6317\n",
      "Epoch 4: loss improved from 2.70670 to 2.63173, saving model to weights-improvement-04-2.6317.hdf5\n",
      "1130/1130 [==============================] - 358s 316ms/step - loss: 2.6317\n",
      "Epoch 5/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.5645\n",
      "Epoch 5: loss improved from 2.63173 to 2.56454, saving model to weights-improvement-05-2.5645.hdf5\n",
      "1130/1130 [==============================] - 357s 316ms/step - loss: 2.5645\n",
      "Epoch 6/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.5073\n",
      "Epoch 6: loss improved from 2.56454 to 2.50734, saving model to weights-improvement-06-2.5073.hdf5\n",
      "1130/1130 [==============================] - 360s 318ms/step - loss: 2.5073\n",
      "Epoch 7/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.4544\n",
      "Epoch 7: loss improved from 2.50734 to 2.45442, saving model to weights-improvement-07-2.4544.hdf5\n",
      "1130/1130 [==============================] - 361s 319ms/step - loss: 2.4544\n",
      "Epoch 8/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.4110\n",
      "Epoch 8: loss improved from 2.45442 to 2.41100, saving model to weights-improvement-08-2.4110.hdf5\n",
      "1130/1130 [==============================] - 362s 321ms/step - loss: 2.4110\n",
      "Epoch 9/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.3628\n",
      "Epoch 9: loss improved from 2.41100 to 2.36279, saving model to weights-improvement-09-2.3628.hdf5\n",
      "1130/1130 [==============================] - 357s 316ms/step - loss: 2.3628\n",
      "Epoch 10/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.3238\n",
      "Epoch 10: loss improved from 2.36279 to 2.32377, saving model to weights-improvement-10-2.3238.hdf5\n",
      "1130/1130 [==============================] - 359s 318ms/step - loss: 2.3238\n",
      "Epoch 11/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2808\n",
      "Epoch 11: loss improved from 2.32377 to 2.28078, saving model to weights-improvement-11-2.2808.hdf5\n",
      "1130/1130 [==============================] - 357s 316ms/step - loss: 2.2808\n",
      "Epoch 12/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2401\n",
      "Epoch 12: loss improved from 2.28078 to 2.24009, saving model to weights-improvement-12-2.2401.hdf5\n",
      "1130/1130 [==============================] - 357s 316ms/step - loss: 2.2401\n",
      "Epoch 13/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2062\n",
      "Epoch 13: loss improved from 2.24009 to 2.20624, saving model to weights-improvement-13-2.2062.hdf5\n",
      "1130/1130 [==============================] - 356s 315ms/step - loss: 2.2062\n",
      "Epoch 14/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.1681\n",
      "Epoch 14: loss improved from 2.20624 to 2.16813, saving model to weights-improvement-14-2.1681.hdf5\n",
      "1130/1130 [==============================] - 360s 318ms/step - loss: 2.1681\n",
      "Epoch 15/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.1323\n",
      "Epoch 15: loss improved from 2.16813 to 2.13231, saving model to weights-improvement-15-2.1323.hdf5\n",
      "1130/1130 [==============================] - 358s 317ms/step - loss: 2.1323\n",
      "Epoch 16/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.0986\n",
      "Epoch 16: loss improved from 2.13231 to 2.09859, saving model to weights-improvement-16-2.0986.hdf5\n",
      "1130/1130 [==============================] - 361s 319ms/step - loss: 2.0986\n",
      "Epoch 17/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.0678\n",
      "Epoch 17: loss improved from 2.09859 to 2.06776, saving model to weights-improvement-17-2.0678.hdf5\n",
      "1130/1130 [==============================] - 360s 318ms/step - loss: 2.0678\n",
      "Epoch 18/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.0385\n",
      "Epoch 18: loss improved from 2.06776 to 2.03848, saving model to weights-improvement-18-2.0385.hdf5\n",
      "1130/1130 [==============================] - 362s 320ms/step - loss: 2.0385\n",
      "Epoch 19/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.0098\n",
      "Epoch 19: loss improved from 2.03848 to 2.00979, saving model to weights-improvement-19-2.0098.hdf5\n",
      "1130/1130 [==============================] - 361s 319ms/step - loss: 2.0098\n",
      "Epoch 20/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 1.9834\n",
      "Epoch 20: loss improved from 2.00979 to 1.98340, saving model to weights-improvement-20-1.9834.hdf5\n",
      "1130/1130 [==============================] - 361s 319ms/step - loss: 1.9834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6379a52a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a723b17",
   "metadata": {},
   "source": [
    "Загрузка наилучшего результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65eb96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-20-1.9834.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e8539b",
   "metadata": {},
   "source": [
    "Вывод сгенерированного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a478b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" so _very_ remarkable in that; nor did alice think it\n",
      "so _very_ much out of the way to hear the rabbi \"\n",
      "t soee and the tabbit soeered an in sar  “hn whu  whl  you knew thet would bell ho the was  soen i sesuld thing you dan  iy was an in ”\n",
      "\n",
      "“h whst io ”ou saad the mertee dirse to tee seet ”ou aan,” said the maccht  “io would hes here to tee shet mote you dan  io do weu,”\n",
      "\n",
      "“ho mo wou dan ”our seit tou dan,” said the katter. “io soedt the seaet saad to the sabbit soee if the had so the taabi saad \n",
      "“hn mo would hane toet io the haree so tee seat soedl then ”ou whue tel ohee ano the sabe th the seae the sabd th the sabbit soee if the had so the tabli. and she was soin a gin fren ti thel  and see toon the tabdit to tee shet sare all the was so tie sare bnd the tan oo the sabbit so the shoee the was soe kintee  and see then she was soe winle taadi to tee shet sere the was so tay an the cauerrirl raatit she saadit soee in the tael  she had not the har hn the wan oo the taile  and saed to the crypo.\n",
      "\n",
      "“io you dan’t think ” said the maccit  “io you toene i was to the worls to toe boole. and the se\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ab0c3",
   "metadata": {},
   "source": [
    "Создание собсвенного callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccff6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(Callback):\n",
    "    def __init__(self, data, int_to_char):\n",
    "        self.dataX = dataX\n",
    "        self.int_to_char = int_to_char\n",
    "    \n",
    "    def text_generation(self):\n",
    "        start = numpy.random.randint(0, n_patterns-1)\n",
    "        pattern = self.dataX[start]\n",
    "        text = []\n",
    "        for i in range(100):\n",
    "            x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "            x = x / float(n_vocab)\n",
    "            prediction = model.predict(x, verbose=0)\n",
    "            index = numpy.argmax(prediction)\n",
    "            result = self.int_to_char[index]\n",
    "            text.append(result)\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:len(pattern)]\n",
    "        return \"\".join(text)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Epoch\", epoch, \"\\n\")\n",
    "            text_gen = self.text_generation()\n",
    "            print(\"Generated text:\", text_gen, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355a4e4",
   "metadata": {},
   "source": [
    "Создаём callback для TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d312e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "CallTB = TensorBoard(log_dir=\"tb_logs\", histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbd44a",
   "metadata": {},
   "source": [
    "Объединяем созданные callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13f6897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath= \"myCallback-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint, CallTB, MyCallback(dataX, int_to_char)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81caa506",
   "metadata": {},
   "source": [
    "Создаём архитектуру ИНС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "646f1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(y.shape[1], activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "697f065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 3.0182\n",
      "Epoch 1: loss improved from inf to 3.01823, saving model to myCallback-weights-improvement-01-3.0182.hdf5\n",
      "Epoch 0 \n",
      "\n",
      "Generated text:  *      *      *      *      *      *      *      *      *      *      *      *      *      *      * \n",
      "\n",
      "1130/1130 [==============================] - 366s 323ms/step - loss: 3.0182\n",
      "Epoch 2/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.8062\n",
      "Epoch 2: loss improved from 3.01823 to 2.80620, saving model to myCallback-weights-improvement-02-2.8062.hdf5\n",
      "1130/1130 [==============================] - 364s 322ms/step - loss: 2.8062\n",
      "Epoch 3/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.7061\n",
      "Epoch 3: loss improved from 2.80620 to 2.70609, saving model to myCallback-weights-improvement-03-2.7061.hdf5\n",
      "1130/1130 [==============================] - 405s 358ms/step - loss: 2.7061\n",
      "Epoch 4/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.6316\n",
      "Epoch 4: loss improved from 2.70609 to 2.63157, saving model to myCallback-weights-improvement-04-2.6316.hdf5\n",
      "1130/1130 [==============================] - 361s 319ms/step - loss: 2.6316\n",
      "Epoch 5/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.5669\n",
      "Epoch 5: loss improved from 2.63157 to 2.56693, saving model to myCallback-weights-improvement-05-2.5669.hdf5\n",
      "1130/1130 [==============================] - 367s 324ms/step - loss: 2.5669\n",
      "Epoch 6/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.5093\n",
      "Epoch 6: loss improved from 2.56693 to 2.50932, saving model to myCallback-weights-improvement-06-2.5093.hdf5\n",
      "Epoch 5 \n",
      "\n",
      "Generated text:                                                                                                      \n",
      "\n",
      "1130/1130 [==============================] - 371s 328ms/step - loss: 2.5093\n",
      "Epoch 7/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.4574\n",
      "Epoch 7: loss improved from 2.50932 to 2.45743, saving model to myCallback-weights-improvement-07-2.4574.hdf5\n",
      "1130/1130 [==============================] - 366s 324ms/step - loss: 2.4574\n",
      "Epoch 8/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.4075\n",
      "Epoch 8: loss improved from 2.45743 to 2.40751, saving model to myCallback-weights-improvement-08-2.4075.hdf5\n",
      "1130/1130 [==============================] - 363s 321ms/step - loss: 2.4075\n",
      "Epoch 9/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.3646\n",
      "Epoch 9: loss improved from 2.40751 to 2.36457, saving model to myCallback-weights-improvement-09-2.3646.hdf5\n",
      "1130/1130 [==============================] - 364s 322ms/step - loss: 2.3646\n",
      "Epoch 10/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.3237\n",
      "Epoch 10: loss improved from 2.36457 to 2.32368, saving model to myCallback-weights-improvement-10-2.3237.hdf5\n",
      "1130/1130 [==============================] - 366s 324ms/step - loss: 2.3237\n",
      "Epoch 11/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2836\n",
      "Epoch 11: loss improved from 2.32368 to 2.28356, saving model to myCallback-weights-improvement-11-2.2836.hdf5\n",
      "Epoch 10 \n",
      "\n",
      "Generated text: eon.\n",
      "“it would hev here to tee soee if the had so the saae th the saab thin soee if the had so the s \n",
      "\n",
      "1130/1130 [==============================] - 369s 327ms/step - loss: 2.2836\n",
      "Epoch 12/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2470\n",
      "Epoch 12: loss improved from 2.28356 to 2.24695, saving model to myCallback-weights-improvement-12-2.2470.hdf5\n",
      "1130/1130 [==============================] - 362s 320ms/step - loss: 2.2470\n",
      "Epoch 13/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2107\n",
      "Epoch 13: loss improved from 2.24695 to 2.21069, saving model to myCallback-weights-improvement-13-2.2107.hdf5\n",
      "1130/1130 [==============================] - 406s 359ms/step - loss: 2.2107\n",
      "Epoch 14/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.1760\n",
      "Epoch 14: loss improved from 2.21069 to 2.17603, saving model to myCallback-weights-improvement-14-2.1760.hdf5\n",
      "1130/1130 [==============================] - 382s 338ms/step - loss: 2.1760\n",
      "Epoch 15/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.1428\n",
      "Epoch 15: loss improved from 2.17603 to 2.14276, saving model to myCallback-weights-improvement-15-2.1428.hdf5\n",
      "1130/1130 [==============================] - 383s 339ms/step - loss: 2.1428\n",
      "Epoch 16/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2075\n",
      "Epoch 16: loss did not improve from 2.14276\n",
      "Epoch 15 \n",
      "\n",
      "Generated text: logog oo the thine then she was soi winl tie sar anw the dar and the sabbit soee and eer setee an in \n",
      "\n",
      "1130/1130 [==============================] - 375s 332ms/step - loss: 2.2075\n",
      "Epoch 17/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.4370\n",
      "Epoch 17: loss did not improve from 2.14276\n",
      "1130/1130 [==============================] - 376s 333ms/step - loss: 2.4370\n",
      "Epoch 18/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2943\n",
      "Epoch 18: loss did not improve from 2.14276\n",
      "1130/1130 [==============================] - 376s 332ms/step - loss: 2.2943\n",
      "Epoch 19/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.2243\n",
      "Epoch 19: loss did not improve from 2.14276\n",
      "1130/1130 [==============================] - 385s 341ms/step - loss: 2.2243\n",
      "Epoch 20/20\n",
      "1130/1130 [==============================] - ETA: 0s - loss: 2.1774\n",
      "Epoch 20: loss did not improve from 2.14276\n",
      "1130/1130 [==============================] - 393s 347ms/step - loss: 2.1774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1459280a050>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44bb01",
   "metadata": {},
   "source": [
    "Загрузка наилучшего результата "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74f244fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"myCallback-weights-improvement-15-2.1428.hdf5\"\n",
    "model1.load_weights(filename)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46215466",
   "metadata": {},
   "source": [
    "Вывод сгенерированного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c910a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" eir heads are gone, if it please your majesty!” the soldiers shouted\n",
      "in reply.\n",
      "\n",
      "“that’s right!” shou \"\n",
      "ght alice, “in wou doe’t know the toiee ”h\n",
      "toedk th the looe tf the lorte ”\n",
      "\n",
      "“he mo thet ao a loog taad ” said the caterpillar.\n",
      "\n",
      "“ier ai _ou d toop then toe seit ”ou ”enl the seit ” said the qoeen, “and the more tf tha lott an in the toiee ”h\n",
      "toenk the mooe tf the loot ”oth ier hend ”ou toone ”hu  the moee tu the toiee ”huh the wou sf the loote ”\n",
      "\n",
      "“he mo thet ao a loog taad ” said the caterpillar.\n",
      "\n",
      "“ier ai _ou d toop then toe seit ”ou ”enl the seit ” said the qoeen, “and the more tf tha lott an in the toiee ”h\n",
      "toenk the mooe tf the loot ”oth ier hend ”ou toone ”hu  the moee tu the toiee ”huh the wou sf the loote ”\n",
      "\n",
      "“he mo thet ao a loog taad ” said the caterpillar.\n",
      "\n",
      "“ier ai _ou d toop then toe seit ”ou ”enl the seit ” said the qoeen, “and the more tf tha lott an in the toiee ”h\n",
      "toenk the mooe tf the loot ”oth ier hend ”ou toone ”hu  the moee tu the toiee ”huh the wou sf the loote ”\n",
      "\n",
      "“he mo thet ao a loog taad ” said the caterpillar.\n",
      "\n",
      "“ier ai _ou d toop then toe seit ”ou ”enl the seit ”\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model1.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93db19cf",
   "metadata": {},
   "source": [
    "Временные ряды для слоя Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23bf9c9",
   "metadata": {},
   "source": [
    "![](dense.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24036736",
   "metadata": {},
   "source": [
    "Временные ряды для слоя LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cc0c0",
   "metadata": {},
   "source": [
    "![](lstm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b934b",
   "metadata": {},
   "source": [
    "График потерь для нашей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39e25a",
   "metadata": {},
   "source": [
    "![](epoch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e92d33",
   "metadata": {},
   "source": [
    "Гистограмма распредления значения на слое Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff66e9",
   "metadata": {},
   "source": [
    "![](dist_dense.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb82ae2",
   "metadata": {},
   "source": [
    "Гистограмма распредления значения на слое LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97034ac4",
   "metadata": {},
   "source": [
    "![](dist_lstm.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
