{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f76584",
   "metadata": {},
   "source": [
    "# БФИ2001 Фаттахов Тагир"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f38b2c",
   "metadata": {},
   "source": [
    "## Лабораторная работа №7 (Классификация обзоров фильмов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe51e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Convolution1D, MaxPooling1D, Dropout, Average\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.utils.data_utils import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce22ea0",
   "metadata": {},
   "source": [
    "Загрузка данных imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3551ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520ba4e",
   "metadata": {},
   "source": [
    "Уравниваем длину входной последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce39d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54837357",
   "metadata": {},
   "source": [
    "Задаем архитекутру реккурентной ИНС и обучаем её"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f944cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_8 (Embedding)     (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "391/391 [==============================] - 324s 824ms/step - loss: 0.4631 - accuracy: 0.7823 - val_loss: 0.3858 - val_accuracy: 0.8323\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 329s 841ms/step - loss: 0.2934 - accuracy: 0.8825 - val_loss: 0.3244 - val_accuracy: 0.8682\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 333s 851ms/step - loss: 0.2516 - accuracy: 0.8996 - val_loss: 0.3078 - val_accuracy: 0.8741\n",
      "Accuracy: 87.41%\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "model_input = Input(shape=(max_review_length,))\n",
    "embed = Embedding(top_words, embedding_vecor_length, input_length=max_review_length)(model_input)\n",
    "lstm = LSTM(100)(embed)\n",
    "out = Dense(1, activation='sigmoid')(lstm)\n",
    "model = Model(inputs=model_input, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07115287",
   "metadata": {},
   "source": [
    "Задаем архитектуру сверточной ИНС и обучаем её"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31fab153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "391/391 [==============================] - 162s 410ms/step - loss: 0.4016 - accuracy: 0.8002 - val_loss: 0.3013 - val_accuracy: 0.8753\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 155s 397ms/step - loss: 0.2415 - accuracy: 0.9049 - val_loss: 0.3263 - val_accuracy: 0.8712\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 144s 369ms/step - loss: 0.1956 - accuracy: 0.9261 - val_loss: 0.2994 - val_accuracy: 0.8801\n",
      "Accuracy: 88.01%\n"
     ]
    }
   ],
   "source": [
    "model1_input = Input(shape=(max_review_length,))\n",
    "embd1 = Embedding(top_words, embedding_vecor_length, input_length=max_review_length)(model1_input)\n",
    "conv_1 = Convolution1D(filters=32, kernel_size=3, padding='same', activation='relu')(embd1)\n",
    "pool_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
    "lstm1 = LSTM(100)(pool_1)\n",
    "out1 = Dense(1, activation='sigmoid')(lstm1)\n",
    "model1 = Model(inputs=model1_input, outputs=out1)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "scores1 = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores1[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12074aa2",
   "metadata": {},
   "source": [
    "Задаем архитектуру сверточной ИНС со слоями Dropout и обучаем её"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476a8fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "391/391 [==============================] - 401s 1s/step - loss: 0.4401 - accuracy: 0.7768 - val_loss: 0.2841 - val_accuracy: 0.8853\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 394s 1s/step - loss: 0.2509 - accuracy: 0.9005 - val_loss: 0.2868 - val_accuracy: 0.8807\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 391s 1s/step - loss: 0.2070 - accuracy: 0.9219 - val_loss: 0.3155 - val_accuracy: 0.8792\n",
      "Accuracy: 87.92%\n"
     ]
    }
   ],
   "source": [
    "model2_input = Input(shape=(max_review_length,))\n",
    "embd2 = Embedding(top_words, embedding_vecor_length, input_length=max_review_length)(model2_input)\n",
    "conv_2 = Convolution1D(filters=32, kernel_size=3, padding='same', activation='relu')(embd2)\n",
    "pool_2 = MaxPooling1D(pool_size=2)(conv_2)\n",
    "drop2_1 = Dropout(0.25)(pool_2)\n",
    "lstm2 = LSTM(100)(drop2_1)\n",
    "drop2_2 = Dropout(0.25)(lstm2)\n",
    "out2 = Dense(1, activation='sigmoid')(drop2_2)\n",
    "model2 = Model(inputs=model2_input, outputs=out2)\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "scores2 = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d777e94",
   "metadata": {},
   "source": [
    "Задаем архитектуру второй сверточной ИНС с слоями Dropout и обучаем её"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c520f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "391/391 [==============================] - 364s 923ms/step - loss: 0.4521 - accuracy: 0.7659 - val_loss: 0.3482 - val_accuracy: 0.8527\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 355s 909ms/step - loss: 0.2702 - accuracy: 0.8939 - val_loss: 0.2843 - val_accuracy: 0.8824\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 346s 885ms/step - loss: 0.2252 - accuracy: 0.9130 - val_loss: 0.3018 - val_accuracy: 0.8777\n",
      "Accuracy: 87.77%\n"
     ]
    }
   ],
   "source": [
    "model3_input = Input(shape=(max_review_length,))\n",
    "embd3 = Embedding(top_words, embedding_vecor_length, input_length=max_review_length)(model3_input)\n",
    "drop3_1 = Dropout(0.25)(embd3)\n",
    "conv_3 = Convolution1D(filters=32, kernel_size=3, padding='same', activation='relu')(drop3_1)\n",
    "pool_3 = MaxPooling1D(pool_size=2)(conv_3)\n",
    "drop3_2 = Dropout(0.25)(pool_3)\n",
    "lstm3 = LSTM(100)(drop3_2)\n",
    "out3 = Dense(1, activation='sigmoid')(lstm3)\n",
    "model3 = Model(inputs=model3_input, outputs=out3)\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "scores3 = model3.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores3[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b45ee4",
   "metadata": {},
   "source": [
    "Производим ансамблирование 4 нейронных сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cce2bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.29%\n"
     ]
    }
   ],
   "source": [
    "ensemble1 = Average()([out, out1, out2, out3])\n",
    "ensemble1 = Dense(1, activation='sigmoid')(ensemble1)\n",
    "ensembleModel1 = Model(inputs=[model_input, model1_input, model2_input, model3_input], outputs=ensemble1, name='ensemble')\n",
    "ensembleModel1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "ensembleModel1.fit([X_train, X_train, X_train, X_train], y_train, epochs=3, batch_size=64, validation_data=([X_test, X_test, X_test, X_test], y_test))\n",
    "scoresEns1 = ensembleModel1.evaluate([X_test, X_test, X_test, X_test], y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scoresEns1[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b550b7",
   "metadata": {},
   "source": [
    "Обзоры фильма (отрицательный и положительный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ee368fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = \"\"\"\n",
    "Either. something, broke or deteriorated in me\n",
    "or the eternal evil cynic Tarantino got tired \n",
    "and also lost his already shaky affection for\n",
    "humanity And a large amount of positive criticism\n",
    "looks like inertia respect for the master and \n",
    "the search for meaning where there is none\n",
    "In all absolutely all of Tarantino's films \n",
    "there was something that justified cruelty \n",
    "there were charming heroes who despite everything\n",
    "were pitied they forced to empathize It was a daring story \n",
    "In the film there is none of the above \n",
    "it's three hours of tedious chatter against the background \n",
    "of very beautiful American landscapes and some kind of boundless cruelty\n",
    "which for obvious reasons cannot be taken seriously \n",
    "but it's generally unclear how it relates\n",
    "All the wonderful actors involved in the film seem to be puppets\n",
    "and obey the will of the mad director The only casting decision\n",
    "that surprised me was Channing Tatum in this rather familiar company \n",
    "His output although episodic is memorable\n",
    "In general I was thinking hard after the film \n",
    "for which Tarantino films are loved To be honest \n",
    "I stopped understanding And all \n",
    "these games of symbols that cause the audience's delight \n",
    "about eights seem very superficial\n",
    "\"\"\"\n",
    "\n",
    "positive = \"\"\"\n",
    "As for me, this film is a film not only about\n",
    "disgusting characters in the style of a\n",
    "western, but also about demonstrating real directorial art.\n",
    "The film is conversational, shot indoors, in 1-2 locations, \n",
    "built on dialogues and narration. And as always, \n",
    "the dialogues in this movie are just fantastic. \n",
    "Just imagine 'Pumping music is playing, crackling \n",
    "fire in the fireplace, a blizzard is blowing outside \n",
    "the window, a western, the main characters are sipping \n",
    "hot coffee and something is about to happen. And all \n",
    "this takes place in a small single wooden house \n",
    "in the middle of a whole wasteland \n",
    "This is where the action of the film unfolds. I've always\n",
    "wondered how Tarantino can convey the whole \n",
    "essence of the characters to the smallest detail \n",
    "with conversations and at the same time attract \n",
    "the viewer. The music is chosen just perfectly, \n",
    "an absolutely deserved Golden Globe. And for \n",
    "so many unpredictable and fascinating scenarios, \n",
    "you can safely award an Oscar. I can't ignore \n",
    "Jennifer's simply magnificent game, which was \n",
    "simply gorgeous in this movie!\n",
    "The Abominable Eight is a film in which the authors \n",
    "have turned out everything: music, script, acting, \n",
    "dialogues, camerawork, the mesmerizing winter atmosphere \n",
    "of a western. And accusing Tarantino of filming the \n",
    "same thing is like accusing a person of speaking his native language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9510d94",
   "metadata": {},
   "source": [
    "Функция распознования настроения текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22ecf105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(text):\n",
    "    arr = ensembleModel1.predict([text,text,text,text])\n",
    "    if(arr[0,0] > 0.50):\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b95018",
   "metadata": {},
   "source": [
    "Функция по преобразованию текста в список значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15ba2f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "film1: negative\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "film2: positive\n"
     ]
    }
   ],
   "source": [
    "def text_set(text: str):\n",
    "    index = imdb.get_word_index()\n",
    "    text = text.replace(',', '')\n",
    "    text = text.replace('.', '')\n",
    "    arr_text = text.lower().split()\n",
    "    index_text = [index.get(word, -4) + 3 for word in arr_text]\n",
    "    index_text_res = []\n",
    "    for a in index_text:\n",
    "        if a > 0 and a < 5000:\n",
    "            index_text_res.append(a)\n",
    "    index_text_res = np.array([index_text_res])\n",
    "    result = pad_sequences(index_text_res, maxlen=max_review_length)\n",
    "    return result\n",
    "\n",
    "b = text_set(negative)\n",
    "print(\"film1:\", predict_class(b))\n",
    "\n",
    "b = text_set(positive)\n",
    "print(\"film2:\", predict_class(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
